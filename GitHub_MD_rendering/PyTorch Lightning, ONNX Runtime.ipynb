{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** PyTorch Lightning, ONNX Runtime\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.482099Z",
     "start_time": "2020-10-27T03:04:26.183212Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# change default style figure and font size\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the credit card default dataset from UCI, we can download this dataset from [Kaggle](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset) as well.\n",
    "\n",
    "There are many ways to implement the data preprocessing step, the high-level idea is to implement the following workflow:\n",
    "\n",
    "- perform train/validation/test split.\n",
    "- encode categorical columns as distinct numerical ids.\n",
    "- standardize numerical columns.\n",
    "- save the preprocesed data.\n",
    "\n",
    "Here, we chose to preprocess the data once and save the output, so we won't have to go through these preprocessing steps every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.615893Z",
     "start_time": "2020-10-27T03:04:28.484929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
""      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = '../DATASETS/UCI_Credit_Card.csv'\n",
    "df = pd.read_csv(input_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.657558Z",
     "start_time": "2020-10-27T03:04:28.618660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of categorical columns:  3\n",
      "number of numerical columns:  20\n"
     ]
    }
   ],
   "source": [
    "id_cols = ['ID']\n",
    "cat_cols = ['EDUCATION', 'SEX', 'MARRIAGE']\n",
    "num_cols = [\n",
    "    'LIMIT_BAL', 'AGE',\n",
    "    'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "    'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "    'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'\n",
    "]\n",
    "label_col = 'default.payment.next.month'\n",
    "\n",
    "print('number of categorical columns: ', len(cat_cols))\n",
    "print('number of numerical columns: ', len(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.802434Z",
     "start_time": "2020-10-27T03:04:28.659992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (18900, 25)\n",
      "validation shape:  (8100, 25)\n",
      "test shape:  (3000, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9256</th>\n",
       "      <td>9257</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23220</th>\n",
       "      <td>23221</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11074</th>\n",
       "      <td>11075</td>\n",
       "      <td>260000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1584</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17793.0</td>\n",
       "      <td>18224.0</td>\n",
       "      <td>18612.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>8624</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3971.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
""      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "9256    9257    20000.0    2          3         1   23      1      2      2   \n",
       "23220  23221   150000.0    2          3         2   35     -1      2     -1   \n",
       "11074  11075   260000.0    2          2         1   43      2      2      2   \n",
       "1583    1584    50000.0    2          1         2   70      2      2      0   \n",
       "8623    8624   390000.0    2          2         1   45      1     -2     -2   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "9256      -2  ...        0.0        0.0        0.0     480.0       0.0   \n",
       "23220      2  ...     1143.0      163.0     2036.0       0.0    2264.0   \n",
       "11074      2  ...     2500.0     2500.0     2500.0       0.0       0.0   \n",
       "1583       0  ...    17793.0    18224.0    18612.0       0.0    2200.0   \n",
       "8623      -2  ...        0.0        0.0        0.0       0.0       0.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "9256        0.0       0.0       0.0       0.0                           1  \n",
       "23220       0.0     163.0    2036.0       0.0                           0  \n",
       "11074       0.0       0.0       0.0       0.0                           1  \n",
       "1583      700.0     700.0     674.0     608.0                           0  \n",
       "8623        0.0       0.0       0.0    3971.0                           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.1\n",
    "val_size = 0.3\n",
    "random_state = 1234\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    stratify=df[label_col])\n",
    "\n",
    "df_train, df_val = train_test_split(\n",
    "    df_train,\n",
    "    test_size=val_size,\n",
    "    random_state=random_state,\n",
    "    stratify=df_train[label_col])\n",
    "\n",
    "print('train shape: ', df_train.shape)\n",
    "print('validation shape: ', df_val.shape)\n",
    "print('test shape: ', df_test.shape)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.847396Z",
     "start_time": "2020-10-27T03:04:28.805515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDUCATION': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6},\n",
       " 'SEX': {1: 0, 2: 1},\n",
       " 'MARRIAGE': {0: 0, 1: 1, 2: 2, 3: 3}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the category code mapping, so we can encode any new incoming data\n",
    "# other than our training set\n",
    "cat_code_dict = {}\n",
    "for col in cat_cols:\n",
    "    category_col = df_train[col].astype('category')\n",
    "    cat_code_dict[col] = {value: idx for idx, value in enumerate(category_col.cat.categories)} \n",
    "\n",
    "cat_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.900305Z",
     "start_time": "2020-10-27T03:04:28.849839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:28.940970Z",
     "start_time": "2020-10-27T03:04:28.901959Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(df, scaler, cat_code_dict, num_cols, cat_cols, label_col):\n",
    "    df = df.copy()\n",
    "\n",
    "    # numeric fields\n",
    "    df[num_cols] = scaler.transform(df[num_cols])\n",
    "    df[num_cols] = df[num_cols].astype(np.float32)\n",
    "\n",
    "    # categorical fields\n",
    "    for col in cat_cols:\n",
    "        code_dict = cat_code_dict[col]\n",
    "        code_fillna_value = len(code_dict)\n",
    "        df[col] = df[col].map(code_dict).fillna(\n",
    "            code_fillna_value).astype(np.int64)\n",
    "\n",
    "    # label\n",
    "    df[label_col] = df[label_col].astype(np.float32)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:29.849670Z",
     "start_time": "2020-10-27T03:04:28.943352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                              int64\n",
       "LIMIT_BAL                     float32\n",
       "SEX                             int64\n",
       "EDUCATION                       int64\n",
       "MARRIAGE                        int64\n",
       "AGE                           float32\n",
       "PAY_0                         float32\n",
       "PAY_2                         float32\n",
       "PAY_3                         float32\n",
       "PAY_4                         float32\n",
       "PAY_5                         float32\n",
       "PAY_6                         float32\n",
       "BILL_AMT1                     float32\n",
       "BILL_AMT2                     float32\n",
       "BILL_AMT3                     float32\n",
       "BILL_AMT4                     float32\n",
       "BILL_AMT5                     float32\n",
       "BILL_AMT6                     float32\n",
       "PAY_AMT1                      float32\n",
       "PAY_AMT2                      float32\n",
       "PAY_AMT3                      float32\n",
       "PAY_AMT4                      float32\n",
       "PAY_AMT5                      float32\n",
       "PAY_AMT6                      float32\n",
       "default.payment.next.month    float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups = {\n",
    "    'train': df_train,\n",
    "    'val': df_val,\n",
    "    'test': df_test\n",
    "}\n",
    "\n",
    "data_dir = 'onnx_data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "for name, df_group in df_groups.items():\n",
    "    filename = os.path.join(data_dir, f'{name}.csv')\n",
    "    df_preprocessed = preprocess(df_group, scaler, cat_code_dict, num_cols, cat_cols, label_col)\n",
    "    df_preprocessed.to_csv(filename, index=False)\n",
    "\n",
    "df_preprocessed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few code chunk involves understanding how to work with [Pytorch's Dataset and DataLoader](https://pytorch.org/docs/stable/data.html). We define a custom Dataset that allows us the load our preprocessed .csv file, and extract the numerical, categorical, and label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:29.888854Z",
     "start_time": "2020-10-27T03:04:29.851805Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:29.931182Z",
     "start_time": "2020-10-27T03:04:29.891258Z"
    }
   },
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, num_cols, cat_cols, label_col):\n",
    "        self.path = path\n",
    "        self.num_cols = num_cols\n",
    "        self.cat_cols = cat_cols\n",
    "        self.label_col = label_col\n",
    "        self.df = read_data(path, num_cols, cat_cols, label_col)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        num_array = self.df[self.num_cols].iloc[idx].values\n",
    "        cat_array = self.df[self.cat_cols].iloc[idx].values\n",
    "        label_array = self.df[self.label_col].iloc[idx]\n",
    "        return num_array, cat_array, label_array\n",
    "\n",
    "\n",
    "def read_data(path, num_cols, cat_cols, label_col):\n",
    "    float_cols = num_cols + [label_col]\n",
    "    dtype = {col: np.float32 for col in float_cols}\n",
    "    dtype.update({col: np.int64 for col in cat_cols})\n",
    "    return pd.read_csv(path, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.057735Z",
     "start_time": "2020-10-27T03:04:29.936792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical value tensor:\n",
      " tensor([[-1.1365, -1.3578,  0.8985,  1.7693,  1.8037, -1.5156, -1.5167, -1.4744,\n",
      "         -0.4939, -0.4858, -0.6720, -0.6725, -0.6630, -0.6509, -0.3129, -0.2444,\n",
      "         -0.3072, -0.2983, -0.3092, -0.2845],\n",
      "        [-0.1374, -0.0537, -0.8610,  1.7693, -0.6883,  1.9076, -0.6384, -0.6082,\n",
      "         -0.6658, -0.6794, -0.6392, -0.6544, -0.6602, -0.6161, -0.3424, -0.1522,\n",
      "         -0.3072, -0.2882, -0.1755, -0.2845]])\n",
      "categorical value tensor:\n",
      " tensor([[3, 1, 1],\n",
      "        [3, 1, 2]])\n",
      "label tensor:\n",
      " tensor([1., 0.])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "path_train = os.path.join(data_dir, 'train.csv')\n",
    "dataset = TabularDataset(path_train, num_cols, cat_cols, label_col)\n",
    "data_loader = DataLoader(dataset, batch_size)\n",
    "\n",
    "# our data loader now returns batches of numerical/categorical/label tensor\n",
    "num_tensor, cat_tensor, label_tensor = next(iter(data_loader))\n",
    "\n",
    "print('numerical value tensor:\\n', num_tensor)\n",
    "print('categorical value tensor:\\n', cat_tensor)\n",
    "print('label tensor:\\n', label_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that one serious downside for this particular dataset implementation is it reads the entire data into memory, for large datasets, this might not be feasible. We'll leave out this enhancements for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Lightning Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be leveraging [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/en/latest/) for organizing our neural network model. I personally find it helpful when it comes to standardizing the structure, and avoid manually writing the training loop compared to vanilla PyTorch. This part is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.109820Z",
     "start_time": "2020-10-27T03:04:30.060356Z"
    }
   },
   "outputs": [],
   "source": [
    "class TabularDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir, num_cols, cat_cols, label_col, num_workers=2,\n",
    "                 batch_size_train=128, batch_size_val=64, batch_size_test=512):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.num_cols = num_cols\n",
    "        self.cat_cols = cat_cols\n",
    "        self.label_col = label_col\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size_train = batch_size_train\n",
    "        self.batch_size_val = batch_size_val\n",
    "        self.batch_size_test = batch_size_test\n",
    "\n",
    "    def setup(self, stage):\n",
    "        num_cols = self.num_cols\n",
    "        cat_cols = self.cat_cols\n",
    "        label_col = self.label_col\n",
    "        \n",
    "        path_train = os.path.join(self.data_dir, 'train.csv')\n",
    "        self.dataset_train = TabularDataset(path_train, num_cols, cat_cols, label_col)\n",
    "\n",
    "        path_val = os.path.join(self.data_dir, 'val.csv')\n",
    "        self.dataset_val = TabularDataset(path_val, num_cols, cat_cols, label_col)\n",
    "\n",
    "        path_test = os.path.join(self.data_dir, 'test.csv')\n",
    "        self.dataset_test = TabularDataset(path_test, num_cols, cat_cols, label_col)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset_train,\n",
    "            num_workers=self.num_workers,\n",
    "            batch_size=self.batch_size_train,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset_val,\n",
    "            num_workers=self.num_workers,\n",
    "            batch_size=self.batch_size_val,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset_test,\n",
    "            num_workers=self.num_workers,\n",
    "            batch_size=self.batch_size_test,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the highlights of using deep learning with tabular data is to create an embedding layer for each of our categorical features, and concatenate them together with the rest of the other numerical features.\n",
    "\n",
    "```\n",
    "embedding(categorical feature 1) ---\n",
    "                                   |\n",
    "embedding(categorical feature 2) ---------> rest of the layers\n",
    "                                   |\n",
    "numerical features -----------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.159556Z",
     "start_time": "2020-10-27T03:04:30.112294Z"
    }
   },
   "outputs": [],
   "source": [
    "class TabularNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, num_cols, cat_cols, embedding_size_dict, n_classes,\n",
    "                 embedding_dim_dict=None, learning_rate=0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        # pytorch lightning black magic, all the arguments can now be\n",
    "        # accessed through self.hparams.[argument]\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.embeddings, total_embedding_dim = self._create_embedding_layers(\n",
    "            cat_cols, embedding_size_dict, embedding_dim_dict)\n",
    "        \n",
    "        # concatenate the numerical variables and the embedding layers\n",
    "        # then proceed with the rest of the sequential flow\n",
    "        in_features = len(num_cols) + total_embedding_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_embedding_layers(cat_cols, embedding_size_dict, embedding_dim_dict):\n",
    "        \"\"\"construct the embedding layer, 1 per each categorical variable\"\"\"\n",
    "        total_embedding_dim = 0\n",
    "        embeddings = {}\n",
    "        for col in cat_cols:\n",
    "            embedding_size = embedding_size_dict[col]\n",
    "            embedding_dim = embedding_dim_dict[col]\n",
    "            total_embedding_dim += embedding_dim\n",
    "            embeddings[col] = nn.Embedding(embedding_size, embedding_dim)\n",
    "\n",
    "        return nn.ModuleDict(embeddings), total_embedding_dim\n",
    "\n",
    "    def forward(self, num_tensor, cat_tensor):\n",
    "\n",
    "        # run through all the categorical variables through its\n",
    "        # own embedding layer and concatenate them together\n",
    "        cat_outputs = []\n",
    "        for i, col in enumerate(self.hparams.cat_cols):\n",
    "            embedding = self.embeddings[col]\n",
    "            cat_output = embedding(cat_tensor[:, i])\n",
    "            cat_outputs.append(cat_output)\n",
    "        \n",
    "        cat_outputs = torch.cat(cat_outputs, dim=1)\n",
    "        \n",
    "        # concatenate the categorical embedding and numerical layer\n",
    "        all_outputs = torch.cat((num_tensor, cat_outputs), dim=1)\n",
    "        \n",
    "        # for binary classification or regression we don't need the additional dimension\n",
    "        final_outputs = self.layers(all_outputs).squeeze(dim=1)\n",
    "        return final_outputs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.compute_loss(batch, batch_idx)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def compute_loss(self, batch, batch_idx):\n",
    "        num_tensor, cat_tensor, label_tensor = batch\n",
    "        output_tensor = self(num_tensor, cat_tensor)\n",
    "        loss = F.binary_cross_entropy_with_logits(output_tensor, label_tensor)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters including the number of layers, units per layer and the embedding size below are all chosen in a somewhat arbitrary manner, feel free to perform some hyperparameter tuning or tweak the layer definition for better performance.\n",
    "\n",
    "For example, when we don't specify the number of embeddings for our categorical variable, [fastai](https://docs.fast.ai/tabular.model#emb_sz_rule) defines a default number based on a rule of thumb corresponding to the number of distinct values for that categorical feature.\n",
    "\n",
    "\n",
    "> Through trial and error, this general rule takes the lower of two values:\n",
    "> - A dimension space of 600\n",
    "> - A dimension space equal to 1.6 times the cardinality of the variable to 0.56.\n",
    "\n",
    "```python\n",
    "def emb_sz_rule(n_cat):\n",
    "    \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
    "    return min(600, round(1.6 * n_cat ** 0.56))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.207028Z",
     "start_time": "2020-10-27T03:04:30.162267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDUCATION': 3, 'SEX': 1, 'MARRIAGE': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 1\n",
    "\n",
    "embedding_size_dict = {col: len(code) for col, code in cat_code_dict.items()}\n",
    "embedding_dim_dict = {col: embedding_size // 2 for col, embedding_size in embedding_size_dict.items()}\n",
    "embedding_dim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:04:30.249211Z",
     "start_time": "2020-10-27T03:04:30.208655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularNet(\n",
       "  (embeddings): ModuleDict(\n",
       "    (EDUCATION): Embedding(7, 3)\n",
       "    (SEX): Embedding(2, 1)\n",
       "    (MARRIAGE): Embedding(4, 2)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_data_module = TabularDataModule(data_dir, num_cols, cat_cols, label_col)\n",
    "\n",
    "# we can print out the network architecture for inspection\n",
    "tabular_model = TabularNet(num_cols, cat_cols, embedding_size_dict, n_classes, embedding_dim_dict)\n",
    "tabular_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon defining the data module, and model module, we can pass it to pytorch lightning's `Trainer` which abstracts the manual training loop process for end users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss')]\n",
    "trainer = pl.Trainer(max_epochs=8, callbacks=callbacks)\n",
    "trainer.fit(tabular_model, tabular_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show how we can use the trained model for inference and evaluation on the test set. For the evaluation, we'll use standard binary classification evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:50.837267Z",
     "start_time": "2020-10-27T03:09:50.757808Z"
    }
   },
   "outputs": [],
   "source": [
    "tabular_model.eval()\n",
    "with torch.no_grad():\n",
    "    model_pred = tabular_model(num_tensor, cat_tensor).cpu().numpy()\n",
    "\n",
    "model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:50.910780Z",
     "start_time": "2020-10-27T03:09:50.839308Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(tabular_model, tabular_data_module):\n",
    "    data_loader = tabular_data_module.test_dataloader()\n",
    "    batch_size = data_loader.batch_size\n",
    "    n_rows = len(tabular_data_module.dataset_test)\n",
    "    \n",
    "    y_true = np.zeros(n_rows, dtype=np.float32)\n",
    "    y_pred = np.zeros(n_rows, dtype=np.float32)\n",
    "    with torch.no_grad():\n",
    "        idx = 0\n",
    "        for num_batch, cat_batch, label_batch in data_loader:\n",
    "            y_output = tabular_model(num_batch, cat_batch)\n",
    "\n",
    "            # we convert the output value to binary classification probability\n",
    "            # with a sigmoid operation, note that this step is specific to the\n",
    "            # problem at hand, and might not apply to say a regression problem\n",
    "            y_prob = torch.sigmoid(y_output).cpu().numpy()\n",
    "\n",
    "            start_idx = idx\n",
    "            idx += batch_size\n",
    "            end_idx = idx\n",
    "            y_pred[start_idx:end_idx] = y_prob\n",
    "            y_true[start_idx:end_idx] = label_batch.cpu().numpy()\n",
    "\n",
    "            if end_idx == n_rows:\n",
    "                break\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:53.690111Z",
     "start_time": "2020-10-27T03:09:50.912891Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = predict(tabular_model, tabular_data_module)\n",
    "y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:53.777836Z",
     "start_time": "2020-10-27T03:09:53.692402Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def compute_score(y_true, y_pred, round_digits=3):\n",
    "    log_loss = round(metrics.log_loss(y_true, y_pred), round_digits)\n",
    "    auc = round(metrics.roc_auc_score(y_true, y_pred), round_digits)\n",
    "\n",
    "    precision, recall, threshold = metrics.precision_recall_curve(y_true, y_pred)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    mask = ~np.isnan(f1)\n",
    "    f1 = f1[mask]\n",
    "    precision = precision[mask]\n",
    "    recall = recall[mask]\n",
    "\n",
    "    best_index = np.argmax(f1)\n",
    "    threshold = round(threshold[best_index], round_digits)\n",
    "    precision = round(precision[best_index], round_digits)\n",
    "    recall = round(recall[best_index], round_digits)\n",
    "    f1 = round(f1[best_index], round_digits)\n",
    "\n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'threshold': threshold,\n",
    "        'log_loss': log_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:53.846320Z",
     "start_time": "2020-10-27T03:09:53.779838Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:56.688300Z",
     "start_time": "2020-10-27T03:09:53.848509Z"
    }
   },
   "outputs": [],
   "source": [
    "tabular_model_loaded = TabularNet.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "tabular_model_loaded.eval()\n",
    "with torch.no_grad():\n",
    "    model_pred_loaded = tabular_model_loaded(num_tensor, cat_tensor).cpu().numpy()\n",
    "\n",
    "y_true, y_pred = predict(tabular_model_loaded, tabular_data_module)\n",
    "compute_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform model inferencing in production, we can export our PyTorch model into ONNX format, and run it using [ONNX Runtime](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html).\n",
    "\n",
    "We'll first run a sample inference using the original PyTorch model and compare it with the output from ONNX Runtime to verfiy the result matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:56.774236Z",
     "start_time": "2020-10-27T03:09:56.690747Z"
    }
   },
   "outputs": [],
   "source": [
    "tabular_model.eval()\n",
    "with torch.no_grad():\n",
    "    torch_pred = tabular_model(num_tensor, cat_tensor).cpu().numpy()\n",
    "\n",
    "torch_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While exporting our model into ONNX format there are a couple of key parameters that we should specify.\n",
    "\n",
    "- Names of the input/output. Instead of leaving it blank, and letting the underlying engine auto-generate the values, this makes our ONNX model easier to work with during inferencing stage.\n",
    "- dynamic_axes. While exporting the model, we need to pass a sample input to inform the underlying engine about the size/shape. While doing so, it's important that we also specify the first dimension (batch size) of our model to be dynamic. This ensures during inferencing stage, the input batch size will not be fixed to the sample input's batch size we provided, but can take on any dynamic value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:56.908870Z",
     "start_time": "2020-10-27T03:09:56.776344Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = 'model.onnx'\n",
    "args = num_tensor, cat_tensor\n",
    "input_names = ['num_tensor', 'cat_tensor']\n",
    "output_names = ['score']\n",
    "dynamic_axes = {\n",
    "    'num_tensor': {0 : 'batch_size'},\n",
    "    'cat_tensor' : {0 : 'batch_size'}\n",
    "}\n",
    "\n",
    "torch.onnx.export(\n",
    "    tabular_model,\n",
    "    args,\n",
    "    filepath,\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    dynamic_axes=dynamic_axes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T03:09:57.019169Z",
     "start_time": "2020-10-27T03:09:56.911238Z"
    }
   },
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "# create the onnx runtime with the exported .onnx model file \n",
    "ort_session = onnxruntime.InferenceSession(filepath)\n",
    "\n",
    "# during inference time, we can be very specific about inputs and outputs\n",
    "ort_inputs = {\n",
    "    'num_tensor': num_tensor.detach().numpy(),\n",
    "    'cat_tensor': cat_tensor.detach().numpy()\n",
    "}\n",
    "# call .run on the onnx runtime session with the desired input and output\n",
    "# the output is a list, but we only need the first output for this example\n",
    "ort_pred = ort_session.run(['score'], ort_inputs)[0]\n",
    "\n",
    "np.allclose(torch_pred, ort_pred)\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\n",
    "ort_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we converted our model to an onnx format, we can also leverage APIs in different languages to run the inference step. e.g. [onnxruntime's Java API](https://github.com/microsoft/onnxruntime/blob/master/docs/Java_API.md) for performing scoring on a JVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- https://github.com/ethen8181/machine-learning/blob/master/deep_learning/tabular/tabular.ipynb\n",
    "- [Blog: An Introduction to Deep Learning for Tabular Data](https://www.fast.ai/2018/04/29/categorical-embeddings/)\n",
    "- [Blog: How 20th Century Fox uses ML to predict a movie audience](https://cloud.google.com/blog/products/ai-machine-learning/how-20th-century-fox-uses-ml-to-predict-a-movie-audience)\n",
    "- [Paper: Covington, Paul and Adams, Jay and Sargin, Emre - Deep Neural Networks for YouTube Recommendations (2016)](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)\n",
    "- [Paper: Haldar, Malay and Abdool, Mustafa and Ramanathan, Prashant and Xu, Tao and Yang, Shulin and Duan, Huizhong and Zhang, Qing and Barrow-Williams, Nick and Turnbull, Bradley C. and Collins, Brendan M. and Legrand, Thomas - Applying Deep Learning To Airbnb Search (2018)](https://arxiv.org/abs/1810.09591)\n",
    "- [PyTorch Documentation - Exporting A Model From PyTorch To ONNX And Running It Using ONNX Runtime](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html)\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225.27px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
